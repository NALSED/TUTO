# ğŸ¤– Installation et Configuration  d''un model Ai en Local. ğŸ¤–

---

##  1ï¸âƒ£ ğŸ¥¼ Labo + Solution ğŸ¥¼

* #### `Labo`
    * #### RTX 4080super VRAM 16GB
    * #### i9 13900kf
    * #### 64 GB ddr5 4800

* #### `Solution`
    * #### CUDA (Compute Unified Device Architecture) : CUDA transforme la carte graphique NVIDIA en superprocesseur parallÃ¨le capable dâ€™effectuer des milliers dâ€™opÃ©rations en mÃªme temps.
    * #### Ollama Ollama est une plateforme et un outil conÃ§u pour faciliter lâ€™utilisation des grands modÃ¨les de langage (LLM) en local sur ton ordinateur.
    * #### DeepSeek Coder 6.7B : est un modÃ¨le de langage spÃ©cialisÃ© dans la gÃ©nÃ©ration de code informatique, la configuration systÃ¨me, lâ€™administration rÃ©seau, le DevOps.
    * #### OpenWebUI : interface web open-source qui permet dâ€™interagir facilement avec des modÃ¨les de langage locaux (LLM) via un navigateur.

  ---
## 2ï¸âƒ£ ğŸ’¾ installation ğŸ’¾

* #### 1) `CUDA`
#### [TÃ©lÃ©charger](https://developer.nvidia.com/cuda-downloads) et installer CUDA.
